{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa5956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3983b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # tutorial은 1.12.0+cu102 base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c174a",
   "metadata": {},
   "source": [
    "# 데이터 작업하기\n",
    "- PyTorch에는 데이터 작업을 위한 기본 요소 두가지인`torch.utills.data.DataLoader` 와 `torch.utils.data.Dataset` 이 있다.\n",
    "    \n",
    "    \n",
    "- `Dataset`은 샘플과 라벨을 저장하고, `DataLoader`는 `Dataset`을 순회하는 Iterable 객체로 감싼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d1c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df2c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      " ================================\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(training_data, '\\n','===='*8)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e46d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112af58",
   "metadata": {},
   "source": [
    "- `Dataset`을 `DataLoader`의 인자로 전달한다. 이는 데이터셋을 Iterable 객체로 감싸고 자동화된 배치, 샘플링, 셔플 및 멀티프로세스 데이터 로딩을 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbccd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1257175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x [N, C, H, W]: torch.Size([64, 1, 28, 28]), torch.float32\n",
      "Shape of y:[Label Number]: torch.Size([64]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "for x,y in test_dataloader:\n",
    "    print(f'Shape of x [N, C, H, W]: {x.shape}, {x.dtype}')\n",
    "    print(f'Shape of y:[Label Number]: {y.shape}, {y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb999c7",
   "metadata": {},
   "source": [
    "- 데이터는 `(64, 1, 28, 28)` 로 `28 * 28 * 1` 의 이미지를 `64개` 갖고있다.\n",
    "    - 64개인 이유는 batch_size가 64이기 때문.\n",
    "- 이미지가 64개이기에 Label 또한 64이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1c217",
   "metadata": {},
   "source": [
    "## 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bf986",
   "metadata": {},
   "source": [
    "- PyTorch에서 신경망 모델은 `nn.Module`을 상속받는 클래스를 생성하여 정의한다. `__init__` 함수에서 신경망의 계층을 정의하고 `forward` 함수에서 신경망에 데이터를 어떻게 전달할지 지정한다. 가능하다면 `GPU`를 사용하여 연산을 가속한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d337429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 디바이스는 cuda 입니다.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"사용 가능한 디바이스는 {device} 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b67201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    1. flatten을 통해 28*28*1 의 크기였던 사진을 1차원으로 바꾸어줌. -> 784 size\n",
    "    2. Sequencial한 linear layer를 통해 784 -> 512 -> 10 의 크기로 변환 해줌\n",
    "    3. 변환된 값을 return\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28*28, 512),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512,512),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512,10)\n",
    "                                              )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf6a16",
   "metadata": {},
   "source": [
    "## 모델 매개변수 최적화하기\n",
    "- 모델을 학습하려면 `손실 함수(loss function)`과 `옵티마이저(optimizer)`가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "304abcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c25a92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # x = 이미지 , y = 라벨\n",
    "        \n",
    "        pred = model(x)\n",
    "        # pred = 예측 텐서\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad() # 가중치 초기화\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "631e7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2de3778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      " ========================\n",
      "size : 60000\n"
     ]
    }
   ],
   "source": [
    "# 1. size = len(dataloader.dataset)\n",
    "\n",
    "print(train_dataloader.dataset, '\\n','===='*6)\n",
    "print('size :', len(train_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "723d9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.033136 [    0/60000]\n",
      "loss: 2.017495 [ 6400/60000]\n",
      "loss: 1.914361 [12800/60000]\n",
      "loss: 1.950931 [19200/60000]\n",
      "loss: 1.862954 [25600/60000]\n",
      "loss: 1.802603 [32000/60000]\n",
      "loss: 1.826298 [38400/60000]\n",
      "loss: 1.726144 [44800/60000]\n",
      "loss: 1.746195 [51200/60000]\n",
      "loss: 1.651227 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.653641 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.698215 [    0/60000]\n",
      "loss: 1.669007 [ 6400/60000]\n",
      "loss: 1.518018 [12800/60000]\n",
      "loss: 1.589838 [19200/60000]\n",
      "loss: 1.471955 [25600/60000]\n",
      "loss: 1.450207 [32000/60000]\n",
      "loss: 1.467201 [38400/60000]\n",
      "loss: 1.379751 [44800/60000]\n",
      "loss: 1.418831 [51200/60000]\n",
      "loss: 1.318145 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.336320 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.400632 [    0/60000]\n",
      "loss: 1.385539 [ 6400/60000]\n",
      "loss: 1.219246 [12800/60000]\n",
      "loss: 1.320307 [19200/60000]\n",
      "loss: 1.200355 [25600/60000]\n",
      "loss: 1.214832 [32000/60000]\n",
      "loss: 1.234418 [38400/60000]\n",
      "loss: 1.162265 [44800/60000]\n",
      "loss: 1.209787 [51200/60000]\n",
      "loss: 1.122962 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.137401 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.201594 [    0/60000]\n",
      "loss: 1.206328 [ 6400/60000]\n",
      "loss: 1.024710 [12800/60000]\n",
      "loss: 1.154060 [19200/60000]\n",
      "loss: 1.029875 [25600/60000]\n",
      "loss: 1.058758 [32000/60000]\n",
      "loss: 1.091827 [38400/60000]\n",
      "loss: 1.024474 [44800/60000]\n",
      "loss: 1.074985 [51200/60000]\n",
      "loss: 1.003421 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.010521 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.064628 [    0/60000]\n",
      "loss: 1.092271 [ 6400/60000]\n",
      "loss: 0.893105 [12800/60000]\n",
      "loss: 1.045776 [19200/60000]\n",
      "loss: 0.922140 [25600/60000]\n",
      "loss: 0.950590 [32000/60000]\n",
      "loss: 0.999594 [38400/60000]\n",
      "loss: 0.935159 [44800/60000]\n",
      "loss: 0.983227 [51200/60000]\n",
      "loss: 0.925025 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.925970 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276f8cd",
   "metadata": {},
   "source": [
    "## 모델 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2e2c5",
   "metadata": {},
   "source": [
    "- 모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을 직렬화(serialize)하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9825345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Saved PyTorch Model State to model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b42f9",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a1356",
   "metadata": {},
   "source": [
    "- 모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "731474a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcdd9864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 예측값: \"T-shirt/top\", 실제값: \"T-shirt/top\"\n",
      "1번째 예측값: \"T-shirt/top\", 실제값: \"T-shirt/top\"\n",
      "2번째 예측값: \"Pullover\", 실제값: \"Pullover\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "for i in range(3):\n",
    "    random_number = random.choice(list(range(len(test_data))))\n",
    "    x, y = test_data[random_number][0], test_data[random_number][1]\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'{i}번째 예측값: \"{predicted}\", 실제값: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
